
Видео детектор возникновения опасных ситуаций на производстве.

## Содержание пакета 

<table>
<tr>
    <td><b> app </b></td>
    <td> Главный функционал, содержит алгоритм детекции опасных ситуаций</td>
</tr>
<tr>
    <td><b> Test </b></td>
    <td> Ноутбук с примером использования алгоритма</td>
</tr>
<tr>
    <td><b> test_images </b></td>
    <td> Примеры изображений для Test</td>
</tr>
<tr>
    <td><b> line_masks </b></td>
    <td> Маски с отмеченными опасными зонами (красные линии) </td>
</tr>
<tr>
    <td><b> camera_vectors </b></td>
    <td> Вектора, используемые для детекции камеры  </td>
</tr>
</table>

## Пример использования 

```python3

from app import predict

#путь к файлу изображения
file = 'test_images/am3_9_violation_frame085.jpg' 

out = predict(file) 
#out содержит список ограничительные рамки для рабочих на изображении, id камеры и логический признак наличия опасной ситуации. 
```

## Описание работы алгоритма  

![Alt text](demo.png?raw=true "")

Ключевая идея - если рабочий подходит к ограничительной линии, то срабатывает детектор. 
Математически  - рассчитывается расстояние между линией, проведенной по нижнему краю забора с некоторым отступом и ближайшим нижним уголом ограничительной прямоугольной рамки человека на изображении. Ближайший угол - нижний левый, если опасная зона находится слева от рабочего и правый нижний, если справа. Там где забор заканчиваться, ограничительная линия продолжается по ограждению и не захватывает недоступные для человека участки. 

Основная метрика качества работы алгоритма Fscore - гармоническое среднее точности P и полноты R. Точность P определяется как отношение количества правильно детектированных ситуации среди всех найденных. Полнота R характеризует, сколько опасных моментов мы нашли из размеченных в наших данных и отражает надежность работы нашего алгоритма. При общении с заказчиком лучше зафиксировать точность P (максимально допустимое количество ложных срабатываний) и обсуждать улучшения надежности R. Так как требуемый уровень R вряд ли будет достигнут в первых итерациях разработки. 

  
В датасете представлены виды с различных камер. Для детекции камеры и выбора соотвествующей маски опасной зоны используется простой KNN с k = 1, с использованием косинусного расстояния в качестве метрики. Вектор картинки и вектора обучающих примеров извлечены с помощью претренированной модели resnet18 из пакета torchvision.models. Дообучение resnet18 не проводилось. Алгоритм и модель выбраны из исходя из минимизации ресурсов на выполнение с сохраниемем качества. Так же был протестирован (на имеющихся данных) и показал свою надежность (RANSAC) random sample consensus. Выбор в пользу resnet18 сделан исходя из экспертной оценки обобщающей способности алгоритма при работе с будущими изображениями. 
  
Стоит отметить, что при реальной эксплуатации алгоритма мы, мы как правило знаем с какой камеры пришло изображение. В этом случае эта часть алгоритма для детекции камеры не нужна. 

Ограничительные рамки людей на изображении получены с помощью модели yolov5s https://pytorch.org/hub/ultralytics_yolov5/. Алгоритм и модель выбраны из исходя из минимизации ресурсов на выполнение при максимальном сохранении качества и рекомендаций разработчиков модели. Более сложные модели, такие как  yolov5m, FasterRCNN, DETR или требуют существенно больше ресурсов на выполнение при небольшом приросте качества или дают ухудшение качества при сравнительном небольшом приросте производительности. Выводы сделаны из анализа результатов полученых на присланном датасете, но могут быть пересмотрены на более полном наборе данных (больше камер, другие локации). 

Сам алгоритм расчета расстояния от человека до опасной зоны разработан исходя из соображений геометрии опасной зоны и априорных предположений о человеческих возможностях. Алгоритм потенциально может давать сбои при перекрытии сцены посторонними предметами и наложении изображений нескольких людей. Так же алгоритм будет плохо работать при ухудшении видимости опасной зоны - задымление, отключение света и т.д. 

## TODO  


Основное направление оптимизации алгоритма - улучшение модели по поиску ограничительных рамок людей. Так как большинство ошибок на предоставленных данных происходило из за неточного определения ограничительной рамки человека. Для этого предлагается провести более детальный анализ SOTA подходов по детекции объектов, возможно что то упущено при первоначальном анализе имеющихся решений. Основной вектор развития - дообучение модели поиска bbox людей на данных из опасной зоны. Для этого рекомедуется собрать больше данных с камер, по возможности соханив баланс количества изображений в обычных условиях работы и условиях нестандартной освещенности и ухудшения видимости. Дополнительно генерировать больше "опасных" моментов не нужно.

Отдельно проанализировать и обработать ситуации с перекрытием ограничительных рамок людей, перекрытием зоны видимости посторонними предметами и ухудшением видимости в опасной зоне.

Так же нужно продумать и реализовать валидацию входящих данных (картинки плохого качества, отсутсвие видимости, картинка с другой камеры, пустое изображение и т.д.). 

Детекция людей в касках и без не реализована. Возможное решение - тренировка модели на базе resnet50 для задачи классификации. Метрика аналогичная - Fscore. Данные для обучения можно извлечь из существующих изображений с камер, после обрезки по ограничительным рамкам, найденным моделью детекции. Скорее всего нужно будет получить больше изображений людей без каски, особенно без растительности на голове, либо в посторонних головных уборах. 
Другое возможно решение - детекция непосредственно каски на изображении. Для него также потребуется сбор данных и обучение модели детекции, а также алгоритм вычисляющий "правильное" положение каски (на голове, а не в руках). При том, что для детекции каски вероятнее всего можно будет дотренировать ту же модель, что и для детекции человека, этот путь видится менее перспективным.

.    





   





 











     






